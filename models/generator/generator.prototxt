layer {
  name: "data1"
  type: "NoiseData"
  top: "data1"
  noise_data_param {
    batch_size: 10
    channels: 3
    spatial_size: 8
    distribution: "uniform"
    min: 0
    max: 1
  }
}
layer {
  name: "block_conv1"
  type: "Convolution"
  bottom: "data1"
  top: "block_conv1"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn1"
  type: "BatchNorm"
  bottom: "block_conv1"
  top: "block_bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu1"
  type: "ReLU"
  bottom: "block_bn1"
  top: "block_bn1"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv2"
  type: "Convolution"
  bottom: "block_bn1"
  top: "block_conv2"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn2"
  type: "BatchNorm"
  bottom: "block_conv2"
  top: "block_bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu2"
  type: "ReLU"
  bottom: "block_bn2"
  top: "block_bn2"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv3"
  type: "Convolution"
  bottom: "block_bn2"
  top: "block_conv3"
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn3"
  type: "BatchNorm"
  bottom: "block_conv3"
  top: "block_bn3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu3"
  type: "ReLU"
  bottom: "block_bn3"
  top: "block_bn3"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_small_nnup1"
  type: "Deconvolution"
  bottom: "block_bn3"
  top: "join_small_nnup1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 8
    stride: 2
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "join_small_bn1"
  type: "BatchNorm"
  bottom: "join_small_nnup1"
  top: "join_small_bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "data2"
  type: "NoiseData"
  top: "data2"
  noise_data_param {
    batch_size: 10
    channels: 3
    spatial_size: 16
    distribution: "uniform"
    min: 0
    max: 1
  }
}
layer {
  name: "block_conv4"
  type: "Convolution"
  bottom: "data2"
  top: "block_conv4"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn4"
  type: "BatchNorm"
  bottom: "block_conv4"
  top: "block_bn4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu4"
  type: "ReLU"
  bottom: "block_bn4"
  top: "block_bn4"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv5"
  type: "Convolution"
  bottom: "block_bn4"
  top: "block_conv5"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn5"
  type: "BatchNorm"
  bottom: "block_conv5"
  top: "block_bn5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu5"
  type: "ReLU"
  bottom: "block_bn5"
  top: "block_bn5"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv6"
  type: "Convolution"
  bottom: "block_bn5"
  top: "block_conv6"
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn6"
  type: "BatchNorm"
  bottom: "block_conv6"
  top: "block_bn6"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu6"
  type: "ReLU"
  bottom: "block_bn6"
  top: "block_bn6"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_large_bn1"
  type: "BatchNorm"
  bottom: "block_bn6"
  top: "join_large_bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "join_concat1"
  type: "Concat"
  bottom: "join_small_bn1"
  bottom: "join_large_bn1"
  top: "join_concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "block_conv7"
  type: "Convolution"
  bottom: "join_concat1"
  top: "block_conv7"
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn7"
  type: "BatchNorm"
  bottom: "block_conv7"
  top: "block_bn7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu7"
  type: "ReLU"
  bottom: "block_bn7"
  top: "block_bn7"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv8"
  type: "Convolution"
  bottom: "block_bn7"
  top: "block_conv8"
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn8"
  type: "BatchNorm"
  bottom: "block_conv8"
  top: "block_bn8"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu8"
  type: "ReLU"
  bottom: "block_bn8"
  top: "block_bn8"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv9"
  type: "Convolution"
  bottom: "block_bn8"
  top: "block_conv9"
  convolution_param {
    num_output: 16
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn9"
  type: "BatchNorm"
  bottom: "block_conv9"
  top: "block_bn9"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu9"
  type: "ReLU"
  bottom: "block_bn9"
  top: "block_bn9"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_small_nnup2"
  type: "Deconvolution"
  bottom: "block_bn9"
  top: "join_small_nnup2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 16
    stride: 2
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "join_small_bn2"
  type: "BatchNorm"
  bottom: "join_small_nnup2"
  top: "join_small_bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "data3"
  type: "NoiseData"
  top: "data3"
  noise_data_param {
    batch_size: 10
    channels: 3
    spatial_size: 32
    distribution: "uniform"
    min: 0
    max: 1
  }
}
layer {
  name: "block_conv10"
  type: "Convolution"
  bottom: "data3"
  top: "block_conv10"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn10"
  type: "BatchNorm"
  bottom: "block_conv10"
  top: "block_bn10"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu10"
  type: "ReLU"
  bottom: "block_bn10"
  top: "block_bn10"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv11"
  type: "Convolution"
  bottom: "block_bn10"
  top: "block_conv11"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn11"
  type: "BatchNorm"
  bottom: "block_conv11"
  top: "block_bn11"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu11"
  type: "ReLU"
  bottom: "block_bn11"
  top: "block_bn11"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv12"
  type: "Convolution"
  bottom: "block_bn11"
  top: "block_conv12"
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn12"
  type: "BatchNorm"
  bottom: "block_conv12"
  top: "block_bn12"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu12"
  type: "ReLU"
  bottom: "block_bn12"
  top: "block_bn12"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_large_bn2"
  type: "BatchNorm"
  bottom: "block_bn12"
  top: "join_large_bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "join_concat2"
  type: "Concat"
  bottom: "join_small_bn2"
  bottom: "join_large_bn2"
  top: "join_concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "block_conv13"
  type: "Convolution"
  bottom: "join_concat2"
  top: "block_conv13"
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn13"
  type: "BatchNorm"
  bottom: "block_conv13"
  top: "block_bn13"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu13"
  type: "ReLU"
  bottom: "block_bn13"
  top: "block_bn13"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv14"
  type: "Convolution"
  bottom: "block_bn13"
  top: "block_conv14"
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn14"
  type: "BatchNorm"
  bottom: "block_conv14"
  top: "block_bn14"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu14"
  type: "ReLU"
  bottom: "block_bn14"
  top: "block_bn14"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv15"
  type: "Convolution"
  bottom: "block_bn14"
  top: "block_conv15"
  convolution_param {
    num_output: 24
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn15"
  type: "BatchNorm"
  bottom: "block_conv15"
  top: "block_bn15"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu15"
  type: "ReLU"
  bottom: "block_bn15"
  top: "block_bn15"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_small_nnup3"
  type: "Deconvolution"
  bottom: "block_bn15"
  top: "join_small_nnup3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 24
    stride: 2
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "join_small_bn3"
  type: "BatchNorm"
  bottom: "join_small_nnup3"
  top: "join_small_bn3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "data4"
  type: "NoiseData"
  top: "data4"
  noise_data_param {
    batch_size: 10
    channels: 3
    spatial_size: 64
    distribution: "uniform"
    min: 0
    max: 1
  }
}
layer {
  name: "block_conv16"
  type: "Convolution"
  bottom: "data4"
  top: "block_conv16"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn16"
  type: "BatchNorm"
  bottom: "block_conv16"
  top: "block_bn16"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu16"
  type: "ReLU"
  bottom: "block_bn16"
  top: "block_bn16"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv17"
  type: "Convolution"
  bottom: "block_bn16"
  top: "block_conv17"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn17"
  type: "BatchNorm"
  bottom: "block_conv17"
  top: "block_bn17"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu17"
  type: "ReLU"
  bottom: "block_bn17"
  top: "block_bn17"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv18"
  type: "Convolution"
  bottom: "block_bn17"
  top: "block_conv18"
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn18"
  type: "BatchNorm"
  bottom: "block_conv18"
  top: "block_bn18"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu18"
  type: "ReLU"
  bottom: "block_bn18"
  top: "block_bn18"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_large_bn3"
  type: "BatchNorm"
  bottom: "block_bn18"
  top: "join_large_bn3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "join_concat3"
  type: "Concat"
  bottom: "join_small_bn3"
  bottom: "join_large_bn3"
  top: "join_concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "block_conv19"
  type: "Convolution"
  bottom: "join_concat3"
  top: "block_conv19"
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn19"
  type: "BatchNorm"
  bottom: "block_conv19"
  top: "block_bn19"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu19"
  type: "ReLU"
  bottom: "block_bn19"
  top: "block_bn19"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv20"
  type: "Convolution"
  bottom: "block_bn19"
  top: "block_conv20"
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn20"
  type: "BatchNorm"
  bottom: "block_conv20"
  top: "block_bn20"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu20"
  type: "ReLU"
  bottom: "block_bn20"
  top: "block_bn20"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv21"
  type: "Convolution"
  bottom: "block_bn20"
  top: "block_conv21"
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn21"
  type: "BatchNorm"
  bottom: "block_conv21"
  top: "block_bn21"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu21"
  type: "ReLU"
  bottom: "block_bn21"
  top: "block_bn21"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_small_nnup4"
  type: "Deconvolution"
  bottom: "block_bn21"
  top: "join_small_nnup4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 32
    stride: 2
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "join_small_bn4"
  type: "BatchNorm"
  bottom: "join_small_nnup4"
  top: "join_small_bn4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "data5"
  type: "NoiseData"
  top: "data5"
  noise_data_param {
    batch_size: 10
    channels: 3
    spatial_size: 128
    distribution: "uniform"
    min: 0
    max: 1
  }
}
layer {
  name: "block_conv22"
  type: "Convolution"
  bottom: "data5"
  top: "block_conv22"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn22"
  type: "BatchNorm"
  bottom: "block_conv22"
  top: "block_bn22"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu22"
  type: "ReLU"
  bottom: "block_bn22"
  top: "block_bn22"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv23"
  type: "Convolution"
  bottom: "block_bn22"
  top: "block_conv23"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn23"
  type: "BatchNorm"
  bottom: "block_conv23"
  top: "block_bn23"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu23"
  type: "ReLU"
  bottom: "block_bn23"
  top: "block_bn23"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv24"
  type: "Convolution"
  bottom: "block_bn23"
  top: "block_conv24"
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn24"
  type: "BatchNorm"
  bottom: "block_conv24"
  top: "block_bn24"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu24"
  type: "ReLU"
  bottom: "block_bn24"
  top: "block_bn24"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_large_bn4"
  type: "BatchNorm"
  bottom: "block_bn24"
  top: "join_large_bn4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "join_concat4"
  type: "Concat"
  bottom: "join_small_bn4"
  bottom: "join_large_bn4"
  top: "join_concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "block_conv25"
  type: "Convolution"
  bottom: "join_concat4"
  top: "block_conv25"
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn25"
  type: "BatchNorm"
  bottom: "block_conv25"
  top: "block_bn25"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu25"
  type: "ReLU"
  bottom: "block_bn25"
  top: "block_bn25"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv26"
  type: "Convolution"
  bottom: "block_bn25"
  top: "block_conv26"
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn26"
  type: "BatchNorm"
  bottom: "block_conv26"
  top: "block_bn26"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu26"
  type: "ReLU"
  bottom: "block_bn26"
  top: "block_bn26"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv27"
  type: "Convolution"
  bottom: "block_bn26"
  top: "block_conv27"
  convolution_param {
    num_output: 40
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn27"
  type: "BatchNorm"
  bottom: "block_conv27"
  top: "block_bn27"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu27"
  type: "ReLU"
  bottom: "block_bn27"
  top: "block_bn27"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_small_nnup5"
  type: "Deconvolution"
  bottom: "block_bn27"
  top: "join_small_nnup5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 40
    stride: 2
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "join_small_bn5"
  type: "BatchNorm"
  bottom: "join_small_nnup5"
  top: "join_small_bn5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "data6"
  type: "NoiseData"
  top: "data6"
  noise_data_param {
    batch_size: 10
    channels: 3
    spatial_size: 256
    distribution: "uniform"
    min: 0
    max: 1
  }
}
layer {
  name: "block_conv28"
  type: "Convolution"
  bottom: "data6"
  top: "block_conv28"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn28"
  type: "BatchNorm"
  bottom: "block_conv28"
  top: "block_bn28"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu28"
  type: "ReLU"
  bottom: "block_bn28"
  top: "block_bn28"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv29"
  type: "Convolution"
  bottom: "block_bn28"
  top: "block_conv29"
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn29"
  type: "BatchNorm"
  bottom: "block_conv29"
  top: "block_bn29"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu29"
  type: "ReLU"
  bottom: "block_bn29"
  top: "block_bn29"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv30"
  type: "Convolution"
  bottom: "block_bn29"
  top: "block_conv30"
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn30"
  type: "BatchNorm"
  bottom: "block_conv30"
  top: "block_bn30"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu30"
  type: "ReLU"
  bottom: "block_bn30"
  top: "block_bn30"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "join_large_bn5"
  type: "BatchNorm"
  bottom: "block_bn30"
  top: "join_large_bn5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "join_concat5"
  type: "Concat"
  bottom: "join_small_bn5"
  bottom: "join_large_bn5"
  top: "join_concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "block_conv31"
  type: "Convolution"
  bottom: "join_concat5"
  top: "block_conv31"
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn31"
  type: "BatchNorm"
  bottom: "block_conv31"
  top: "block_bn31"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu31"
  type: "ReLU"
  bottom: "block_bn31"
  top: "block_bn31"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv32"
  type: "Convolution"
  bottom: "block_bn31"
  top: "block_conv32"
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn32"
  type: "BatchNorm"
  bottom: "block_conv32"
  top: "block_bn32"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu32"
  type: "ReLU"
  bottom: "block_bn32"
  top: "block_bn32"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "block_conv33"
  type: "Convolution"
  bottom: "block_bn32"
  top: "block_conv33"
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}
layer {
  name: "block_bn33"
  type: "BatchNorm"
  bottom: "block_conv33"
  top: "block_bn33"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "block_relu33"
  type: "ReLU"
  bottom: "block_bn33"
  top: "block_bn33"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "block_bn33"
  top: "conv1"
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
    bias_filler {
      type: "msra"
      variance_norm: AVERAGE
    }
  }
}

